\chapter{Introduction générale}

\section{Introduction}

La classification ou la catégorie des images sont importantes pour accéder à l'information visuelle au niveau d'objets, qui consiste à étiqueter automatiquement des images en catégories prédéfinies. Ces méthodes sont largement utilisées tels que : la reconnaissance des scènes naturelles, la reconnaissance des chiffres sur des chèques, la reconnaissance des codes postaux pour la classification automatique des courriers, la reconnaissance des visages pour l'authentification, etc.\\

Dans ce domaine, le résultat de classification n'est pas très exact. Surtout, la vitesse d'apprendre des méthode actuelle est base. Fait face de ce problème, on a besoin d'améliorer la vitesse des méthodes ou développer une autre méthode qui est moins compliqué et qui donne le résultat de classification acceptable. La méthode Descente de Gradient de Stochastique (SGD) est une bon choix pour ce problème. Donc, ce stage fait le point sur la méthode SGD, MC-SGD et sa version parallèle.

\section{Description par chapitre}

Avant de parler de notre travail, dans premier temps, nous allons présenter la théorie de base des méthodes utilisées. Tout d'abord, nous allons présenter la méthode SIFT et la méthode Sac de Mots dans le chapitre \ref{chap:sift}. Ensuite, nous allons présenter l'étape d'apprentissage automatique qui se compose la méthode SVM standard et un version de SVM avec SGD dans le chapitre \ref{chap:sgd}. Dans ce chapitre, nous parlerons aussi des façons pour résoudre le problème de multi-classes avec un classificateur de 2 classes. Dans le second temps, nous présenterons notre implémentation dans le chapitre \ref{chap:impl}. Pour le chapitre \ref{chap:res}, nous présenterons le résultat obtenue et l'analyserons en détaillé. A fin de ce rapport, nous terminerons avec la conclusion et perspective dans le chapitre \ref{chap:con}.