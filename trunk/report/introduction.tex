\addcontentsline{toc}{chapter}{Introduction générale}
\chapter*{Introduction générale}

La classification ou la catégorie des images est importante pour accéder à l'information visuelle au niveau d'objets, qui consiste à étiqueter automatiquement des images en catégories prédéfinies. Ces méthodes sont largement utilisées dans les domaines importants : la reconnaissance des scènes naturelles, la reconnaissance des chiffres sur des chèques, la reconnaissance des codes postaux pour la classification automatique des courriers, la reconnaissance des visages pour l'authentification, etc.\\

Actuellement, le premier stage de la classification d'image est réalisé par extraire des données visuelles dans des images. Le deuxième stage de la classification d'image est qu'on applique une méthode de classification sur des données visuelles pour la classification. Ce processus trouve le problème de données complexes. Particulièrement, la sortie du premier stage comprend la large dimension et le nombre d'exemples est beaucoup.\\

Pour les bases de données complexes, la vitesse d'apprentissage des méthodes de classification actuelle est base. Faire face de ce problème, on a deux options pour l'optimisation. L'une se concentre sur la diminution de la dimension des données, l'autre se concentre sur l'amélioration de la vitesse du stage d'apprentissage. Ce stage est mise le point sur le développement d'un algorithme de classification qui peut prendre des données entrées très complexes. C'est à dire on a choisi la deuxième option, améliorer la vitesse de l'étape d'apprentissage.\\

Pour le stage de classification, il existent plusieurs méthodes tels que : réseau de neurones, quantification vectorielle, arbre de décision, machine des vecteurs de support, etc. Parmi les différents méthodes, la méthode SVM est souvent choisie. Pendant ce stage, nous avons choisi la méthode Descente de Gradient Stochastique (SGD) pour remplacer la méthode SVM en raison de sa simplification et sa efficacité. Au lieu de résoudre le problème de programme quadratique comme la méthode SVM, la méthode SGD apprend par la descente de gradient stochastique. Nous trouvons que la méthode SGD est beaucoup plus rapide que la méthode SVM. Basé sur le SGD binaire, dans ce projet, nous avons développé un algorithme MC-SGD pour la classification multi-classes et le parallélisé. Nous avons aussi développé l'application MC-SGD-Toy pour mieux comprendre ce que le MC-SGD fait à l'interface.

\subsubsection{Description par chapitre}

Avant de parler de notre travail, dans premier temps, nous allons présenter la théorie de base des méthodes utilisées. Tout d'abord, nous allons présenter la méthode SIFT et le modèle Sac de Mots dans le chapitre \ref{chap:sift}. Ensuite, nous allons présenter l'étape d'apprentissage automatique qui se compose la méthode SVM et la méthode SGD dans le chapitre \ref{chap:sgd}. Dans ce chapitre, nous parlerons aussi des façons pour résoudre le problème de multi-classes se basant sur un classificateur de 2 classes. Dans le second temps, nous présenterons notre implémentation dans le chapitre \ref{chap:impl}. Pour le chapitre \ref{chap:exp}, nous présenterons le résultat obtenu et l'analyserons en détaillé. A la fin de ce rapport, nous terminerons avec la conclusion et perspective.